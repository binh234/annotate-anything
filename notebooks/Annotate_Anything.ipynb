{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies"
      ],
      "metadata": {
        "id": "GvhZkQF-LrWY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78Vphb19mDS6"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/binh234/annotate-anything.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd annotate-anything\n",
        "!pip install -q -r requirements.txt"
      ],
      "metadata": {
        "id": "I5ltbBdSmNUT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2fd817c9-971c-4160-93cf-3a57c8aa74d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/facebookresearch/segment-anything.git (from -r requirements.txt (line 30))\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-9j3nfgyr\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-9j3nfgyr\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit 6fdee8f2727f4506cfbbe553e23b895e27956588\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/IDEA-Research/GroundingDINO (from -r requirements.txt (line 31))\n",
            "  Cloning https://github.com/IDEA-Research/GroundingDINO to /tmp/pip-req-build-1lku4o1x\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/IDEA-Research/GroundingDINO /tmp/pip-req-build-1lku4o1x\n",
            "  Resolved https://github.com/IDEA-Research/GroundingDINO to commit 31aa788a3cf6ab82d27385f39e242b34af9cc011\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from -r requirements.txt (line 2))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 3))\n",
            "  Downloading gradio-3.33.1-py3-none-any.whl (20.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface_hub (from -r requirements.txt (line 4))\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.22.4)\n",
            "Collecting onnxruntime (from -r requirements.txt (line 7))\n",
            "  Downloading onnxruntime-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv_python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (8.4.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (2.0.6)\n",
            "Collecting pycocoevalcap (from -r requirements.txt (line 11))\n",
            "  Downloading pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (2.27.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (67.7.2)\n",
            "Collecting supervision (from -r requirements.txt (line 15))\n",
            "  Downloading supervision-0.8.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (2.3.0)\n",
            "Collecting timm (from -r requirements.txt (line 17))\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (0.15.2+cu118)\n",
            "Collecting transformers (from -r requirements.txt (line 20))\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m134.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yapf (from -r requirements.txt (line 21))\n",
            "  Downloading yapf-0.33.0-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.9/200.9 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (0.56.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (1.10.1)\n",
            "Collecting safetensors (from -r requirements.txt (line 24))\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynvml (from -r requirements.txt (line 25))\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairscale (from -r requirements.txt (line 26))\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (0.5.4)\n",
            "Collecting argparse (from -r requirements.txt (line 28))\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 29)) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (5.9.5)\n",
            "Collecting aiofiles (from gradio->-r requirements.txt (line 3))\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting aiohttp (from gradio->-r requirements.txt (line 3))\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 3)) (4.2.2)\n",
            "Collecting fastapi (from gradio->-r requirements.txt (line 3))\n",
            "  Downloading fastapi-0.96.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio->-r requirements.txt (line 3))\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client>=0.2.4 (from gradio->-r requirements.txt (line 3))\n",
            "  Downloading gradio_client-0.2.5-py3-none-any.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.1/288.1 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio->-r requirements.txt (line 3))\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 3)) (2.2.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 3)) (2.1.2)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio->-r requirements.txt (line 3))\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson (from gradio->-r requirements.txt (line 3))\n",
            "  Downloading orjson-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 3)) (1.5.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 3)) (1.10.7)\n",
            "Collecting pydub (from gradio->-r requirements.txt (line 3))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 3)) (2.14.0)\n",
            "Collecting python-multipart (from gradio->-r requirements.txt (line 3))\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version (from gradio->-r requirements.txt (line 3))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 3)) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 3))\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.0 (from gradio->-r requirements.txt (line 3))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r requirements.txt (line 4)) (3.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r requirements.txt (line 4)) (2023.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.2)\n",
            "Collecting coloredlogs (from onnxruntime->-r requirements.txt (line 7))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime->-r requirements.txt (line 7)) (23.3.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime->-r requirements.txt (line 7)) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime->-r requirements.txt (line 7)) (1.11.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 13)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 13)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 13)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 13)) (3.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 18)) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 18)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 18)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 18)) (16.0.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 20)) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->-r requirements.txt (line 20))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->-r requirements.txt (line 21)) (2.0.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->-r requirements.txt (line 22)) (0.39.1)\n",
            "Collecting supervision (from -r requirements.txt (line 15))\n",
            "  Downloading supervision-0.6.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 3)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 3)) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 3)) (0.12.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 3)) (0.1.2)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 3))\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio->-r requirements.txt (line 3)) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 3)) (8.1.3)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 3))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio->-r requirements.txt (line 3)) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->gradio->-r requirements.txt (line 3))\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->gradio->-r requirements.txt (line 3))\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->gradio->-r requirements.txt (line 3))\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->gradio->-r requirements.txt (line 3))\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->gradio->-r requirements.txt (line 3))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->-r requirements.txt (line 7))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio->-r requirements.txt (line 3))\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio->-r requirements.txt (line 3))\n",
            "  Downloading httpcore-0.17.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio->-r requirements.txt (line 3)) (3.6.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r requirements.txt (line 3)) (0.19.3)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 3))\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Building wheels for collected packages: fairscale, segment-anything, groundingdino, ffmpy\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332112 sha256=b3aa51592112ecdf116804804a0187d6321ba51180b3749e4a6711d586a2bfd9\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\n",
            "  Building wheel for segment-anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segment-anything: filename=segment_anything-1.0-py3-none-any.whl size=36589 sha256=770dc11d4bcd91f2cbf186dc39668669dc68f73814789a9fa8907c9aae584681\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mxiybwd_/wheels/10/cf/59/9ccb2f0a1bcc81d4fbd0e501680b5d088d690c6cfbc02dc99d\n",
            "  Building wheel for groundingdino (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for groundingdino: filename=groundingdino-0.1.0-cp310-cp310-linux_x86_64.whl size=3846791 sha256=857286e1f041d1f16b84c5fb6a4c168e8ecbc0537022e831cf6fdba27c95d4d5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mxiybwd_/wheels/85/2b/15/c5a09de5cf3f52e0609c97c8335f8f40f01d4855e46dfd0e26\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=f8507d2afc0655b6bb05fa1c169aeb2c3afd716fa73115ecfb89c0efb72eabf0\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n",
            "Successfully built fairscale segment-anything groundingdino ffmpy\n",
            "Installing collected packages: tokenizers, segment-anything, safetensors, pydub, ffmpy, argparse, addict, yapf, websockets, uc-micro-py, semantic-version, python-multipart, pynvml, orjson, multidict, humanfriendly, h11, frozenlist, async-timeout, aiofiles, yarl, uvicorn, starlette, mdit-py-plugins, linkify-it-py, huggingface_hub, httpcore, coloredlogs, aiosignal, transformers, supervision, onnxruntime, httpx, fastapi, aiohttp, pycocoevalcap, gradio-client, gradio, timm, groundingdino, fairscale, accelerate\n",
            "Successfully installed accelerate-0.19.0 addict-2.4.0 aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 argparse-1.4.0 async-timeout-4.0.2 coloredlogs-15.0.1 fairscale-0.4.13 fastapi-0.96.0 ffmpy-0.3.0 frozenlist-1.3.3 gradio-3.33.1 gradio-client-0.2.5 groundingdino-0.1.0 h11-0.14.0 httpcore-0.17.2 httpx-0.24.1 huggingface_hub-0.15.1 humanfriendly-10.0 linkify-it-py-2.0.2 mdit-py-plugins-0.3.3 multidict-6.0.4 onnxruntime-1.15.0 orjson-3.9.0 pycocoevalcap-1.2 pydub-0.25.1 pynvml-11.5.0 python-multipart-0.0.6 safetensors-0.3.1 segment-anything-1.0 semantic-version-2.10.0 starlette-0.27.0 supervision-0.6.0 timm-0.9.2 tokenizers-0.13.3 transformers-4.29.2 uc-micro-py-1.0.2 uvicorn-0.22.0 websockets-11.0.3 yapf-0.33.0 yarl-1.9.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load models"
      ],
      "metadata": {
        "id": "7OpoNiQoLuY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "import tempfile\n",
        "import torch\n",
        "\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import supervision as sv\n",
        "from PIL import Image\n",
        "from segment_anything import build_sam\n",
        "from segment_anything import SamAutomaticMaskGenerator\n",
        "from segment_anything import SamPredictor\n",
        "from supervision.detection.utils import mask_to_polygons\n",
        "from supervision.detection.utils import xywh_to_xyxy\n",
        "\n",
        "from groundingdino.util.inference import Model as DinoModel\n",
        "\n",
        "sys.path.append(\"tag2text\")\n",
        "\n",
        "from tag2text.models import tag2text\n",
        "from config import *\n",
        "from utils import download_file_hf, detect, segment, show_anns, show_anns_sv, generate_tags"
      ],
      "metadata": {
        "id": "Y4gXYoEnuMYg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(abs_weight_dir):\n",
        "    os.makedirs(abs_weight_dir, exist_ok=True)\n",
        "\n",
        "sam_checkpoint = os.path.join(abs_weight_dir, sam_dict[default_sam][\"checkpoint_file\"])\n",
        "if not os.path.exists(sam_checkpoint):\n",
        "    os.system(f\"wget {sam_dict[default_sam]['checkpoint_url']} -O {sam_checkpoint}\")\n",
        "\n",
        "tag2text_checkpoint = os.path.join(abs_weight_dir, tag2text_dict[default_tag2text][\"checkpoint_file\"])\n",
        "if not os.path.exists(tag2text_checkpoint):\n",
        "    os.system(f\"wget {tag2text_dict[default_tag2text]['checkpoint_url']} -O {tag2text_checkpoint}\")\n",
        "\n",
        "dino_checkpoint = os.path.join(abs_weight_dir, dino_dict[default_dino][\"checkpoint_file\"])\n",
        "dino_config_file = os.path.join(abs_weight_dir, dino_dict[default_dino][\"config_file\"])\n",
        "if not os.path.exists(dino_checkpoint):\n",
        "    dino_repo_id = dino_dict[default_dino][\"repo_id\"]\n",
        "    download_file_hf(repo_id=dino_repo_id, filename=dino_dict[default_dino][\"config_file\"], cache_dir=weight_dir)\n",
        "    download_file_hf(repo_id=dino_repo_id, filename=dino_dict[default_dino][\"checkpoint_file\"], cache_dir=weight_dir)"
      ],
      "metadata": {
        "id": "AbBtq48huG-Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tag2text_model = tag2text.tag2text_caption(\n",
        "    pretrained=tag2text_checkpoint,\n",
        "    image_size=384,\n",
        "    vit=\"swin_b\",\n",
        "    delete_tag_index=delete_tag_index,\n",
        ")\n",
        "# threshold for tagging\n",
        "# we reduce the threshold to obtain more tags\n",
        "tag2text_model.threshold = 0.64\n",
        "tag2text_model.to(device)\n",
        "tag2text_model.eval()\n",
        "\n",
        "\n",
        "sam = build_sam(checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "sam_predictor = SamPredictor(sam)\n",
        "sam_automask_generator = SamAutomaticMaskGenerator(sam)\n",
        "\n",
        "grounding_dino_model = DinoModel(\n",
        "    model_config_path=dino_config_file, model_checkpoint_path=dino_checkpoint\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhCaI9zyuQD4",
        "outputId": "c1eca527-344f-4911-cbcd-5fb2d1bb4899"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/encoder/layer/0/crossattention/self/query is tied\n",
            "/encoder/layer/0/crossattention/self/key is tied\n",
            "/encoder/layer/0/crossattention/self/value is tied\n",
            "/encoder/layer/0/crossattention/output/dense is tied\n",
            "/encoder/layer/0/crossattention/output/LayerNorm is tied\n",
            "/encoder/layer/0/intermediate/dense is tied\n",
            "/encoder/layer/0/output/dense is tied\n",
            "/encoder/layer/0/output/LayerNorm is tied\n",
            "/encoder/layer/1/crossattention/self/query is tied\n",
            "/encoder/layer/1/crossattention/self/key is tied\n",
            "/encoder/layer/1/crossattention/self/value is tied\n",
            "/encoder/layer/1/crossattention/output/dense is tied\n",
            "/encoder/layer/1/crossattention/output/LayerNorm is tied\n",
            "/encoder/layer/1/intermediate/dense is tied\n",
            "/encoder/layer/1/output/dense is tied\n",
            "/encoder/layer/1/output/LayerNorm is tied\n",
            "--------------\n",
            "/content/weights/tag2text_swin_14m.pth\n",
            "--------------\n",
            "load checkpoint from /content/weights/tag2text_swin_14m.pth\n",
            "vit: swin_b\n",
            "msg _IncompatibleKeys(missing_keys=['visual_encoder.layers.0.blocks.0.attn.relative_position_index', 'visual_encoder.layers.0.blocks.1.attn_mask', 'visual_encoder.layers.0.blocks.1.attn.relative_position_index', 'visual_encoder.layers.1.blocks.0.attn.relative_position_index', 'visual_encoder.layers.1.blocks.1.attn_mask', 'visual_encoder.layers.1.blocks.1.attn.relative_position_index', 'visual_encoder.layers.2.blocks.0.attn.relative_position_index', 'visual_encoder.layers.2.blocks.1.attn_mask', 'visual_encoder.layers.2.blocks.1.attn.relative_position_index', 'visual_encoder.layers.2.blocks.2.attn.relative_position_index', 'visual_encoder.layers.2.blocks.3.attn_mask', 'visual_encoder.layers.2.blocks.3.attn.relative_position_index', 'visual_encoder.layers.2.blocks.4.attn.relative_position_index', 'visual_encoder.layers.2.blocks.5.attn_mask', 'visual_encoder.layers.2.blocks.5.attn.relative_position_index', 'visual_encoder.layers.2.blocks.6.attn.relative_position_index', 'visual_encoder.layers.2.blocks.7.attn_mask', 'visual_encoder.layers.2.blocks.7.attn.relative_position_index', 'visual_encoder.layers.2.blocks.8.attn.relative_position_index', 'visual_encoder.layers.2.blocks.9.attn_mask', 'visual_encoder.layers.2.blocks.9.attn.relative_position_index', 'visual_encoder.layers.2.blocks.10.attn.relative_position_index', 'visual_encoder.layers.2.blocks.11.attn_mask', 'visual_encoder.layers.2.blocks.11.attn.relative_position_index', 'visual_encoder.layers.2.blocks.12.attn.relative_position_index', 'visual_encoder.layers.2.blocks.13.attn_mask', 'visual_encoder.layers.2.blocks.13.attn.relative_position_index', 'visual_encoder.layers.2.blocks.14.attn.relative_position_index', 'visual_encoder.layers.2.blocks.15.attn_mask', 'visual_encoder.layers.2.blocks.15.attn.relative_position_index', 'visual_encoder.layers.2.blocks.16.attn.relative_position_index', 'visual_encoder.layers.2.blocks.17.attn_mask', 'visual_encoder.layers.2.blocks.17.attn.relative_position_index', 'visual_encoder.layers.3.blocks.0.attn.relative_position_index', 'visual_encoder.layers.3.blocks.1.attn.relative_position_index'], unexpected_keys=[])\n",
            "final text_encoder_type: bert-base-uncased\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio App"
      ],
      "metadata": {
        "id": "BKw9imiOLwr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process(image_path, task, prompt, box_threshold, text_threshold, iou_threshold):\n",
        "    global tag2text_model, sam_predictor, sam_automask_generator, grounding_dino_model, device\n",
        "    output_gallery = []\n",
        "    detections = None\n",
        "    metadata = {\"image\": {}, \"annotations\": []}\n",
        "\n",
        "    try:\n",
        "        # Load image\n",
        "        image = Image.open(image_path)\n",
        "        image_pil = image.convert(\"RGB\")\n",
        "        image = np.array(image_pil)\n",
        "\n",
        "        # Extract image metadata\n",
        "        filename = os.path.basename(image_path)\n",
        "        h, w = image.shape[:2]\n",
        "        metadata[\"image\"][\"file_name\"] = filename\n",
        "        metadata[\"image\"][\"width\"] = w\n",
        "        metadata[\"image\"][\"height\"] = h\n",
        "\n",
        "        # Generate tags\n",
        "        if task in [\"auto\", \"detection\"] and prompt == \"\":\n",
        "            tags, caption = generate_tags(tag2text_model, image_pil, \"None\", device)\n",
        "            prompt = \" . \".join(tags)\n",
        "            print(f\"Caption: {caption}\")\n",
        "            print(f\"Tags: {tags}\")\n",
        "\n",
        "            # ToDo: Extract metadata\n",
        "            metadata[\"image\"][\"caption\"] = caption\n",
        "            metadata[\"image\"][\"tags\"] = tags\n",
        "\n",
        "        if prompt:\n",
        "            metadata[\"prompt\"] = prompt\n",
        "            print(f\"Prompt: {prompt}\")\n",
        "\n",
        "        # Detect boxes\n",
        "        if prompt != \"\":\n",
        "            detections, phrases, classes = detect(\n",
        "                grounding_dino_model,\n",
        "                image,\n",
        "                caption=prompt,\n",
        "                box_threshold=box_threshold,\n",
        "                text_threshold=text_threshold,\n",
        "                iou_threshold=iou_threshold,\n",
        "                post_process=True,\n",
        "            )\n",
        "\n",
        "            # Draw boxes\n",
        "            box_annotator = sv.BoxAnnotator()\n",
        "            labels = [\n",
        "                f\"{classes[class_id] if class_id else 'Unkown'} {confidence:0.2f}\"\n",
        "                for _, _, confidence, class_id, _ in detections\n",
        "            ]\n",
        "            image = box_annotator.annotate(\n",
        "                scene=image, detections=detections, labels=labels\n",
        "            )\n",
        "            output_gallery.append(image)\n",
        "\n",
        "        # Segmentation\n",
        "        if task in [\"auto\", \"segment\"]:\n",
        "            if detections:\n",
        "                masks, scores = segment(\n",
        "                    sam_predictor, image=image, boxes=detections.xyxy\n",
        "                )\n",
        "                detections.mask = masks\n",
        "            else:\n",
        "                masks = sam_automask_generator.generate(image)\n",
        "                sorted_generated_masks = sorted(\n",
        "                    masks, key=lambda x: x[\"area\"], reverse=True\n",
        "                )\n",
        "\n",
        "                xywh = np.array([mask[\"bbox\"] for mask in sorted_generated_masks])\n",
        "                mask = np.array(\n",
        "                    [mask[\"segmentation\"] for mask in sorted_generated_masks]\n",
        "                )\n",
        "                scores = np.array(\n",
        "                    [mask[\"predicted_iou\"] for mask in sorted_generated_masks]\n",
        "                )\n",
        "                detections = sv.Detections(\n",
        "                    xyxy=xywh_to_xyxy(boxes_xywh=xywh), mask=mask\n",
        "                )\n",
        "                # opacity = 0.4\n",
        "                # mask_image, _ = show_anns(masks)\n",
        "                # annotated_image = np.uint8(mask_image * opacity + image * (1 - opacity))\n",
        "            \n",
        "            mask_annotator = sv.MaskAnnotator()\n",
        "            mask_image = np.zeros_like(image, dtype=np.uint8)\n",
        "            mask_image = mask_annotator.annotate(\n",
        "                mask_image, detections=detections, opacity=1\n",
        "            )\n",
        "            annotated_image = mask_annotator.annotate(image, detections=detections)\n",
        "            output_gallery.append(mask_image)\n",
        "            output_gallery.append(annotated_image)\n",
        "\n",
        "        # ToDo: Extract metadata\n",
        "        if detections:\n",
        "            id = 1\n",
        "            for (xyxy, mask, confidence, class_id, _), area, box_area, score in zip(\n",
        "                detections, detections.area, detections.box_area, scores\n",
        "            ):\n",
        "                annotation = {\n",
        "                    \"id\": id,\n",
        "                    \"bbox\": [int(x) for x in xyxy],\n",
        "                    \"box_area\": float(box_area),\n",
        "                }\n",
        "                if class_id:\n",
        "                    annotation[\"box_confidence\"] = float(confidence)\n",
        "                    annotation[\"label\"] = classes[class_id] if class_id else \"Unkown\"\n",
        "                if mask is not None:\n",
        "                    # annotation[\"segmentation\"] = mask_to_polygons(mask)\n",
        "                    annotation[\"area\"] = int(area)\n",
        "                    annotation[\"predicted_iou\"] = float(score)\n",
        "                metadata[\"annotations\"].append(annotation)\n",
        "                id += 1\n",
        "\n",
        "\n",
        "        meta_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".json\")\n",
        "        meta_file_path = meta_file.name\n",
        "        with open(meta_file_path, \"w\", encoding=\"utf-8\") as fp:\n",
        "            json.dump(metadata, fp)\n",
        "\n",
        "        return output_gallery, meta_file_path\n",
        "    except Exception as error:\n",
        "        raise gr.Error(f\"global exception: {error}\")\n",
        "\n",
        "\n",
        "title = \"Annotate Anything\"\n",
        "\n",
        "with gr.Blocks(css=\"style.css\", title=title) as demo:\n",
        "    with gr.Row(elem_classes=[\"container\"]):\n",
        "        with gr.Column(scale=1):\n",
        "            input_image = gr.Image(type=\"filepath\", label=\"Input\")\n",
        "            task = gr.Dropdown(\n",
        "                [\"detect\", \"segment\", \"auto\"], value=\"auto\", label=\"task_type\"\n",
        "            )\n",
        "            text_prompt = gr.Textbox(label=\"Detection Prompt\")\n",
        "            with gr.Accordion(\"Advanced parameters\", open=False):\n",
        "                box_threshold = gr.Slider(\n",
        "                    minimum=0,\n",
        "                    maximum=1,\n",
        "                    value=0.3,\n",
        "                    step=0.05,\n",
        "                    label=\"Box threshold\",\n",
        "                    info=\"Hash size to use for image hashing\",\n",
        "                )\n",
        "                text_threshold = gr.Slider(\n",
        "                    minimum=0,\n",
        "                    maximum=1,\n",
        "                    value=0.25,\n",
        "                    step=0.05,\n",
        "                    label=\"Text threshold\",\n",
        "                    info=\"Number of history images used to find out duplicate image\",\n",
        "                )\n",
        "                iou_threshold = gr.Slider(\n",
        "                    minimum=0,\n",
        "                    maximum=1,\n",
        "                    value=0.5,\n",
        "                    step=0.05,\n",
        "                    label=\"IOU threshold\",\n",
        "                    info=\"Minimum similarity threshold (in percent) to consider 2 images to be similar\",\n",
        "                )\n",
        "            run_button = gr.Button(label=\"Run\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            gallery = gr.Gallery(\n",
        "                label=\"Generated images\", show_label=False, elem_id=\"gallery\"\n",
        "            ).style(preview=True, grid=2, object_fit=\"scale-down\")\n",
        "            meta_file = gr.File(label=\"Metadata file\")\n",
        "    with gr.Row(elem_classes=[\"container\"]):\n",
        "        gr.Examples(\n",
        "            [\n",
        "                [\"examples/dog.png\", \"auto\", \"\"],\n",
        "                [\"examples/eiffel.jpg\", \"auto\", \"\"],\n",
        "                [\"examples/eiffel.png\", \"segment\", \"\"],\n",
        "                [\"examples/girl.png\", \"auto\", \"girl . face\"],\n",
        "                [\"examples/horse.png\", \"detect\", \"horse\"],\n",
        "                [\"examples/horses.jpg\", \"auto\", \"horse\"],\n",
        "                [\"examples/traffic.jpg\", \"auto\", \"\"],\n",
        "            ],\n",
        "            [input_image, task, text_prompt],\n",
        "        )\n",
        "    run_button.click(\n",
        "        fn=process,\n",
        "        inputs=[\n",
        "            input_image,\n",
        "            task,\n",
        "            text_prompt,\n",
        "            box_threshold,\n",
        "            text_threshold,\n",
        "            iou_threshold,\n",
        "        ],\n",
        "        outputs=[gallery, meta_file],\n",
        "    )\n",
        "\n",
        "demo.queue(concurrency_count=2).launch(debug=True, share=True)\n"
      ],
      "metadata": {
        "id": "WGyHgVVZmSYr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "outputId": "b4cc50c3-a781-4765-add3-7cd110b788da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://7fb68c0fe744f1477c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://7fb68c0fe744f1477c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caption: a poodle that is sitting on a bench\n",
            "Tags: ['poodle', 'field', 'dog', 'park bench', 'bench']\n",
            "Prompt: poodle . field . dog . park bench . bench\n",
            "Before NMS: 3 boxes\n",
            "After NMS: 2 boxes\n",
            "/tmp/tmp213h_a_y.json\n",
            "/tmp/tmpkhiiiyya.json\n",
            "Prompt: horse\n",
            "Before NMS: 1 boxes\n",
            "After NMS: 1 boxes\n",
            "/tmp/tmp73swwyvl.json\n",
            "/tmp/tmp9qevgi50.json\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://7fb68c0fe744f1477c.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Command lines"
      ],
      "metadata": {
        "id": "TUaTtY0BLzMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The metadata file will contain the following information:\n",
        "\n",
        "```text\n",
        "{\n",
        "    \"image\"                 : image_info,\n",
        "    \"annotations\"           : [annotation],\n",
        "}\n",
        "\n",
        "image_info {\n",
        "    \"width\"                 : int,              # Image width\n",
        "    \"height\"                : int,              # Image height\n",
        "    \"file_name\"             : str,              # Image filename\n",
        "    \"caption\"               : str,              # Image caption\n",
        "    \"tags\"                  : [str],            # Image tags\n",
        "}\n",
        "\n",
        "annotation {\n",
        "    \"id\"                    : int,              # Annotation id\n",
        "    \"bbox\"                  : [x1, y1, x2, y2],     # The box around the mask, in XYXY format\n",
        "    \"area\"                  : int,              # The area in pixels of the mask\n",
        "    \"box_area\"              : float,            # The area in pixels of the bounding box\n",
        "    \"predicted_iou\"         : float,            # The model's own prediction of the mask's quality\n",
        "    \"box_confidence\"        : float,            # A measure of the box's quality\n",
        "    \"label\"                 : str,              # Predicted class for the object inside the bounding box (if exist)\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "CVR9v70NJYKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python annotate_anything.py -i examples -o /content/outputs_segment --task segment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goZ_OqwFwfGi",
        "outputId": "173daf9f-9e2f-4504-95ac-599a5418fc52"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-04 15:56:47.478216: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loading SAM...\n",
            "7it [02:08, 18.31s/it, Processing examples/traffic.jpg]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python annotate_anything.py -i examples -o /content/outputs_auto --task auto"
      ],
      "metadata": {
        "id": "Xgl-pBJB2wJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VZAvbh66EdLF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
